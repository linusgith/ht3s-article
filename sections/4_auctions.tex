\section{Auctions} %TODO
\label{sec:auctions}

Not only are FaaS and Fog-Computing dynamic concepts because of the continuous research being done in the respective fields but also due to their core paradigms.
To deal with the constant change these systems are exposed to, it is important to find solutions that are flexible.
To solve the challenges of function placement and load distribution (i.e. where to store a function binary and related data so that it may be executed there) in the heterogeneous, distributed and unreliable environment of Fog Computing, AuctionWhisk employs an auction-inspired approach. 

\subsection{Using auctions for decentralized decision-making}

Auctions offer an approach for making stateless placement decisions on a particular path from the client to the cloud. 
Managing a central source of truth in a distributed system requires much effort and many difficult trade-offs and should hence be avoided if possible. 
Instead, the environment should be able to make decentralized decisions that create a consistent behavior at a high level. 

Auctions can act as such mechanisms since they are characterized through their independence of other systems (e.g., in the real world auctions are mostly uninfluenced by the economy and act as a self-contained market). 
Functions can be efficiently placed with regard to the application's resource needs as well as the cloud providers monetary interests by ranking them by the price a developer is ready to pay. 
Higher bids are executed at the Edge with lower latency while lower bids are executed in closer proximity to the Cloud where resources are more abundant but latency higher. 
This model works particularly well in a fog environment as only little advantage is generated by having shared state among the nodes. 
That is, since the prices should be bound to a location so that individual resource limits are considered. 
For example, the system does not gain an advantage by comparing bids from developers of latency-sensitive applications in (A) a remote resource-constrained region and (B) a metropolitan area with abundant resources, as the scenarios are hardly comparable.

\subsection{Latency effects of auctions}



% Latency can stack up and take not only advantage of fog but provide a disadvantage

Although auctions can save costs for the user while maintaining performance, it can also cause significant performance decrease through auction-induced overhead. 
To determine a winner in an auction, multiple bids must be considered. 
In a quickly evolving environment like FaaS, AuctionWhisk achieves this by aggregating an average over all bids in a timeframe and then admitting those function that offered higher bids than the average. 
This potentially introduces additional latency at two layers. 
Firstly, as the window is aggregated over a certain time period before the winners are determined, functions that arrive early in a window inherit additional latency by having to wait until the window is closed and a decision is made. 
Secondly, if a function should be eliminated during an auction, the call is propagated to the next layer on the path where an auction is held again.
Consequently, the effect can be amplified due to unfortunate timing or an insufficient bid. 
In a case like this, it is likely that there is not only no advantage gained by using a fog infrastructure, but that performance is worse than it would have been, routing the request directly to the cloud. 
That is, since on top of network latency, auction latency is introduced as well. \footnote{Auction latency also includes serialization, deserialization, IO-operations etc.}
This can of course have an impact on the perceived performance-cost ratio of the client.


% Rephrase this better -> maybe this also belongs in my own part?
% For the aforementioned established deployments this means, that assumptions on resources can be made and one of two cases is expected: 
% Either enough resources are available for a request to be executed instantly or requests are queued. From an architecture perspective this is reasonable since there is only one system layer capable of request execution, and we expect it to provide sufficient resources to handle the load.
% Contrarily, for FaaS in a fog environment, a request is forwarded instead of queued, since there are multiple serving layers, and it can not be assumed that a particular one is able to handle all load. 

